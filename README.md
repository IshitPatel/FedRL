# FedRL
A Reinforcement Learning Based Client Selection to optimize training computational overhead in Heterogenous Federated Learning

# ğŸ§  FedRL: A Reinforcement Learning Approach to Adaptive Client Selection in Federated Learning

*A research project by Ishit Patel | MS CS, San Francisco State University*

---

## ğŸ” Overview

**FedRL** is a novel framework that integrates **Deep Q-Network (DQN)**-based reinforcement learning into **Federated Learning (FL)** to intelligently select clients for training. It addresses key challenges in FL such as:

- Non-IID data distribution  
- Unfair client participation  
- High communication and compute overhead

FedRL optimizes client selection in each round to maximize convergence speed and model performance, while ensuring fairness and diversity across participants.

---

## ğŸ¯ Key Features

- âœ… DQN-based adaptive client selection
- ğŸ“‰ 37% faster convergence over FedAvg
- ğŸ“ˆ 12.5% improvement in test accuracy
- âš–ï¸ Fairness-aware selection using participation frequency
- ğŸŒ KL-divergence-based heterogeneity measure
- âš¡ PyTorch + Flower-based scalable FL simulation

---

## ğŸ“š Paper & Report

- ğŸ“„ [Read the project blog series on Medium](https://ishitpatel.medium.com)
- ğŸ“ Full report (PDF available upon request)
- ğŸ“˜ Title: *FedRL: A Reinforcement Learning Approach to Adaptive Client Selection in Federated Learning*

---

## ğŸ§ª Datasets Used

- ğŸ–¼ï¸ **CIFAR-10** with ResNet-18  
- âœï¸ **MNIST** with SimpleCNN  
- Experiments on both **homogeneous** and **heterogeneous (non-IID)** data distributions

---

## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/IshitPatel/FedRL.git
cd FedRL
